# Vision–Language–Action (VLA) Build-Up
A generic self-contained Vision–Language–Action (VLA) model build-up.  
I created a diverse synthetic driving environment and trains 2 models:

- **Vision-only baseline** (CNN → action)
- **Fused VLA model** (CNN + text → fused representation → action)