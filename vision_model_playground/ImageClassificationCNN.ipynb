{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=False)\n",
    "test_data = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=False)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n",
      "tensor([[[-0.5373, -0.6627, -0.6078,  ...,  0.2392,  0.1922,  0.1608],\n",
      "         [-0.8745, -1.0000, -0.8588,  ..., -0.0353, -0.0667, -0.0431],\n",
      "         [-0.8039, -0.8745, -0.6157,  ..., -0.0745, -0.0588, -0.1451],\n",
      "         ...,\n",
      "         [ 0.6314,  0.5765,  0.5529,  ...,  0.2549, -0.5608, -0.5843],\n",
      "         [ 0.4118,  0.3569,  0.4588,  ...,  0.4431, -0.2392, -0.3490],\n",
      "         [ 0.3882,  0.3176,  0.4039,  ...,  0.6941,  0.1843, -0.0353]],\n",
      "\n",
      "        [[-0.5137, -0.6392, -0.6235,  ...,  0.0353, -0.0196, -0.0275],\n",
      "         [-0.8431, -1.0000, -0.9373,  ..., -0.3098, -0.3490, -0.3176],\n",
      "         [-0.8118, -0.9451, -0.7882,  ..., -0.3412, -0.3412, -0.4275],\n",
      "         ...,\n",
      "         [ 0.3333,  0.2000,  0.2627,  ...,  0.0431, -0.7569, -0.7333],\n",
      "         [ 0.0902, -0.0353,  0.1294,  ...,  0.1608, -0.5137, -0.5843],\n",
      "         [ 0.1294,  0.0118,  0.1137,  ...,  0.4431, -0.0745, -0.2784]],\n",
      "\n",
      "        [[-0.5059, -0.6471, -0.6627,  ..., -0.1529, -0.2000, -0.1922],\n",
      "         [-0.8431, -1.0000, -1.0000,  ..., -0.5686, -0.6078, -0.5529],\n",
      "         [-0.8353, -1.0000, -0.9373,  ..., -0.6078, -0.6078, -0.6706],\n",
      "         ...,\n",
      "         [-0.2471, -0.7333, -0.7961,  ..., -0.4510, -0.9451, -0.8431],\n",
      "         [-0.2471, -0.6706, -0.7647,  ..., -0.2627, -0.7333, -0.7333],\n",
      "         [-0.0902, -0.2627, -0.3176,  ...,  0.0980, -0.3412, -0.4353]]])\n"
     ]
    }
   ],
   "source": [
    "class_names = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "image, label = train_data[0]\n",
    "print(image.size())\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 3 input channels, 12 feature maps to produce, 3 * 3 filter (kernel), default stride of 1\n",
    "        self.conv1 = nn.Conv2d(3, 12, 3)   # (32 - 3) / 1 + 1 = 30 pixels. New shape: (12, 30, 30)\n",
    "        \n",
    "        self.pool1 = nn.MaxPool2d(2, 2)    # New shape: (12, 30 / 2 = 15, 30 / 2 = 15)\n",
    "        \n",
    "        # 12 input feature maps, 24 feature maps to produce, 4 * 4 filter (kernel), default stride of 1\n",
    "        self.conv2 = nn.Conv2d(12, 24, 4)  # (15 - 4) / 1 + 1 = 12 pixels. New shape: (24, 12, 12)\n",
    "        \n",
    "        # For better understanding, this max pooling layer is constructed separetely, though it's the same as self.pool1\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)    # New shape: (24, 6, 6)\n",
    "        \n",
    "        # Flatten to 24 * 6 * 6 and output to 128 then 64 neurons and finally 10 classes\n",
    "        self.fc1 = nn.Linear(24 * 6 * 6, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNet()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 1 ...\n",
      "Loss: 2.2688\n",
      "Training epoch 2 ...\n",
      "Loss: 1.8905\n",
      "Training epoch 3 ...\n",
      "Loss: 1.6184\n",
      "Training epoch 4 ...\n",
      "Loss: 1.4486\n",
      "Training epoch 5 ...\n",
      "Loss: 1.3368\n",
      "Training epoch 6 ...\n",
      "Loss: 1.2394\n",
      "Training epoch 7 ...\n",
      "Loss: 1.1599\n",
      "Training epoch 8 ...\n",
      "Loss: 1.0902\n",
      "Training epoch 9 ...\n",
      "Loss: 1.0322\n",
      "Training epoch 10 ...\n",
      "Loss: 0.9838\n",
      "Training epoch 11 ...\n",
      "Loss: 0.9394\n",
      "Training epoch 12 ...\n",
      "Loss: 0.8979\n",
      "Training epoch 13 ...\n",
      "Loss: 0.8601\n",
      "Training epoch 14 ...\n",
      "Loss: 0.8210\n",
      "Training epoch 15 ...\n",
      "Loss: 0.7870\n",
      "Training epoch 16 ...\n",
      "Loss: 0.7547\n",
      "Training epoch 17 ...\n",
      "Loss: 0.7218\n",
      "Training epoch 18 ...\n",
      "Loss: 0.6878\n",
      "Training epoch 19 ...\n",
      "Loss: 0.6559\n",
      "Training epoch 20 ...\n",
      "Loss: 0.6278\n",
      "Training epoch 21 ...\n",
      "Loss: 0.5939\n",
      "Training epoch 22 ...\n",
      "Loss: 0.5662\n",
      "Training epoch 23 ...\n",
      "Loss: 0.5400\n",
      "Training epoch 24 ...\n",
      "Loss: 0.5086\n",
      "Training epoch 25 ...\n",
      "Loss: 0.4806\n",
      "Training epoch 26 ...\n",
      "Loss: 0.4528\n",
      "Training epoch 27 ...\n",
      "Loss: 0.4271\n",
      "Training epoch 28 ...\n",
      "Loss: 0.4051\n",
      "Training epoch 29 ...\n",
      "Loss: 0.3769\n",
      "Training epoch 30 ...\n",
      "Loss: 0.3483\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    print(f'Training epoch {epoch + 1} ...')\n",
    "    \n",
    "    running_loss = 0\n",
    "    \n",
    "    for data in train_loader:\n",
    "        inputs, labels = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    print(f'Loss: {running_loss / len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'trained_net.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_net = NeuralNet()\n",
    "new_net.load_state_dict(torch.load('trained_net.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 68.12%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "new_net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "accuracy = 100 * correct / total\n",
    "\n",
    "print(f'Accuracy: {accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of example1: dog\n",
      "Prediction of example2: car\n"
     ]
    }
   ],
   "source": [
    "new_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "def load_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = new_transform(image)\n",
    "    image = image.unsqueeze(0)  # Images have to be presented as a batch\n",
    "    return image\n",
    "\n",
    "image_paths = ['example1.jpg', 'example2.jpg']  # example1: dog, example2: car\n",
    "images = [load_image(img) for img in image_paths]\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for i, image in enumerate(images):\n",
    "        output = new_net(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        print(f'Prediction of example{i + 1}: {class_names[predicted.item()]}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
